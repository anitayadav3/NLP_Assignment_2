{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2M3IqohXUAc",
        "colab_type": "code",
        "outputId": "ee9da93c-ad9e-4f88-9782-7093a819263b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Import the numpy library to work with and manipulate the data\n",
        "import numpy as np\n",
        "# Import the pandas library to read our dataset\n",
        "import pandas as pd\n",
        "\n",
        "#load the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv',delimiter='\\t')\n",
        "\n",
        "data=data[['Phrase','Sentiment']]\n",
        "#Print the head of data\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Phrase  Sentiment\n",
              "0  A series of escapades demonstrating the adage ...          1\n",
              "1  A series of escapades demonstrating the adage ...          2\n",
              "2                                           A series          2\n",
              "3                                                  A          2\n",
              "4                                             series          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbMq6oi8FVsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f403fe18-b9df-48d9-cf41-6e3715421ddd"
      },
      "source": [
        "data['Sentiment'].value_counts()[:5].plot(kind='barh')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f23af7bcdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLL8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dBcK79lRuQy",
        "colab_type": "code",
        "outputId": "7c73e7bf-0e06-40c7-a582-4d9367295adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Cleaning the data reviews\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "\n",
        "#Clean the phrases text using lemmatization\n",
        "def clean_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        \n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus\n",
        "\n",
        "\n",
        "data['clean_review']=clean_review(data.Phrase.values)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAlO8d-keBPv",
        "colab_type": "code",
        "outputId": "67cf7808-9735-4779-889f-13b0f380d905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "X = data['clean_review']\n",
        "Y = to_categorical(data['Sentiment'].values)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBpC0n8pd7uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Get the train/test split package from sklearn for preparing our dataset to\n",
        "# train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splits the dataset so 70% is used for training and 30% for testing\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig42YKIeebBC",
        "colab_type": "code",
        "outputId": "b05f28ce-1708-48b2-b432-44fb93e2f674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#print the size/shape of the training and testing data\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,) (109242, 5)\n",
            "(46818,) (46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K1b8brBVcDE",
        "colab_type": "code",
        "outputId": "5e716c8e-392c-493f-9085-988016e72df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_words=' '.join(X_train)\n",
        "all_words=word_tokenize(all_words)\n",
        "\n",
        "#Get the frequency distribution of all the words\n",
        "dist_freq=FreqDist(all_words)\n",
        "\n",
        "#Get the number of unique words\n",
        "unique_words=len(dist_freq)\n",
        "unique_words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3o-ch23VtkJ",
        "colab_type": "code",
        "outputId": "ddba16d1-6ec1-48c8-ce73-b0f05ec0caf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Get the length of maximum review text\n",
        "\n",
        "review_len=[]\n",
        "for text in X_train:\n",
        "    word=word_tokenize(text)\n",
        "    l=len(word)\n",
        "    review_len.append(l)\n",
        "    \n",
        "max_rev_len=np.max(review_len)\n",
        "max_rev_len"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXr-OnBC8Dze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining feature length\n",
        "max_features = unique_words\n",
        "max_words = max_rev_len\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XjMg2wgWIVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "#Tokenizing the words to form bag of words\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "#Convert words to sequences\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDGSkRcwWtUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Pad the sequences for handling variable length in reviews \n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHp0u6YhW8Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing keras model, layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "#Defining the CNN Model for the network\n",
        "def cNNModel(max_features, max_words):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Input / Embdedding\n",
        "  model.add(Embedding(max_features, 150, input_length=max_words))\n",
        "\n",
        "  # CNN\n",
        "  model.add(SpatialDropout1D(0.2))\n",
        "\n",
        "  model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "  model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Output layer\n",
        "  model.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbufiVAOXDFx",
        "colab_type": "code",
        "outputId": "708f3a71-034f-40f8-8bdf-41aa4d4730af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Define the model\n",
        "model = cNNModel(max_features, max_words)\n",
        "\n",
        "#Defining number of epochs for the model, number of classes and batch size\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "num_classes=5\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "109242/109242 [==============================] - 23s 206us/step - loss: 1.0311 - acc: 0.5857 - val_loss: 0.8727 - val_acc: 0.6368\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 10s 95us/step - loss: 0.7935 - acc: 0.6698 - val_loss: 0.8298 - val_acc: 0.6503\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 10s 94us/step - loss: 0.7071 - acc: 0.7031 - val_loss: 0.8310 - val_acc: 0.6547\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 10s 95us/step - loss: 0.6441 - acc: 0.7276 - val_loss: 0.8500 - val_acc: 0.6576\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 10s 93us/step - loss: 0.5924 - acc: 0.7480 - val_loss: 0.8695 - val_acc: 0.6541\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 10s 94us/step - loss: 0.5466 - acc: 0.7651 - val_loss: 0.9052 - val_acc: 0.6472\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 10s 96us/step - loss: 0.5092 - acc: 0.7787 - val_loss: 0.9445 - val_acc: 0.6524\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 10s 95us/step - loss: 0.4782 - acc: 0.7898 - val_loss: 1.0075 - val_acc: 0.6482\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 10s 93us/step - loss: 0.4495 - acc: 0.8008 - val_loss: 1.0786 - val_acc: 0.6446\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 10s 93us/step - loss: 0.4269 - acc: 0.8103 - val_loss: 1.0645 - val_acc: 0.6433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f235fd13a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAlcZfZ2gy0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Ri2MPrPSRB",
        "colab_type": "code",
        "outputId": "b1141a21-07db-4c9d-d2c5-2a34d6c0c55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#Mount Google drive to save the model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Go0cmoQNds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model\n",
        "model.save(\"1117437_1dconv_reg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpR6ElVzQp1N",
        "colab_type": "code",
        "outputId": "0162a411-65de-43c6-ab45-d7c9e5291d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "#import and load the model\n",
        "model = load_model('1117437_1dconv_reg')\n",
        "\n",
        "#Printing the summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 48, 150)           2058750   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 48, 150)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 48, 32)            14432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 24, 64)            6208      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 12, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 3845      \n",
            "=================================================================\n",
            "Total params: 2,083,235\n",
            "Trainable params: 2,083,235\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dstNv19hSnLi",
        "colab_type": "code",
        "outputId": "89f31f94-5501-49e8-d13f-1ad0b7daba69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Predicting the classes of the test data\n",
        "\n",
        "pred2=model.predict_classes(X_val,verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46818/46818 [==============================] - 3s 61us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjZjDUKBBSUH",
        "colab_type": "code",
        "outputId": "0b8586ed-c3f5-4499-bdb6-a370d9ce9dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "#Get the report for the test data\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "Y_val=np.argmax(Y_val, axis=1)\n",
        "\n",
        "#Printing the classification report\n",
        "print(classification_report(Y_val, pred2, digits=5))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.49271   0.29847   0.37174      2151\n",
            "           1    0.50901   0.60533   0.55301      8070\n",
            "           2    0.75617   0.74649   0.75130     23987\n",
            "           3    0.55573   0.54801   0.55184      9872\n",
            "           4    0.50859   0.46494   0.48579      2738\n",
            "\n",
            "    accuracy                        0.64326     46818\n",
            "   macro avg    0.56444   0.53265   0.54274     46818\n",
            "weighted avg    0.64472   0.64326   0.64209     46818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}